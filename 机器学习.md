

## SVM 

决策边界（决策平面）——划分两类数据的超平面。

支持向量——距离决策边界最近的点，他们到决策边界的距离称为间隔距离。

间隔——$ \frac{2}{\|w||\ } $，两个异类支持向量到决策边界的距离和，体现两类数据差异的大小，间隔越大划分越容易，超平面划分的也越可靠。

正负超平面——决策边界平移直到与正负类中的支持向量重合

升维转换——如果对于低纬度n下无法用n-1维的超平面划分，通过某维度转换函数升维到更高纬度m或许可以用m-1的超平面划分。并且如果原始空间是有限维度即属性有限的话，那么一定存在一个高维特征空间使得样本可分。

在升维转换应用的情况下，如果不想升维就需要运用核技巧。 本来我们想要将现有向量从低维升到高维，再通过计算向量在高维下的点积来解决min $ \frac{||w||^2}{2} $的对偶问题（采用**SMO**算法也可以减少求解对偶问题的计算量），核函数的基本作用就是接受两个低维空间里的向量，能够计算出经过某个变换后在高维空间里的向量内积值，而不需要具体确定维度转换函数是什么。

- 线性核
- 多项式核
- **高斯核**   以两向量的距离来衡量相似度  σ 表示高斯核的带宽 值越大对距离的要求越严格
- 拉普拉斯核
- Sigmoid核           

### 硬间隔支持向量机

硬间隔是必须完全正确地将正负样本分类前提下的间隔

此时SVM的任务是在满足能完全划分开正负类样本的前提下，最大化间隔 max $ \frac{2}{\|w||\ } $，也等价于 min $ \frac{||w||^2}{2} $

### 软间隔支持向量机

软间隔 ——允许有一定的分类错误，需要计算损失，例如正样本落在正超平面外就会产生损失

问题转化为求解 min f(w) = $ \frac{||w||^2}{2} $ $ +  C×\sum \limits_{i = 1}^{s}\varepsilon i$ ，其中C作为损失的权重

 $ ||w||^2 $ 和  $ \sum \limits_{i = 1}^{s}\varepsilon i $ 相互制约，前者增大时表示间隔减小，原始数据越不容易出现分类错误，总损失相对会小

- **hinge(铰链)损失**
- 指数损失
- 对率损失

### Weeds

支持向量机不能很好的容忍非标准化数据,所以强烈建议先将数据标准化后在训练



准确度 accuracy_score

roc(AUC)   plot_roc_curve

predict_proba   predict   decision_function

## 决策树

不同决策树算法使用的属性划分指标：

ID3 ：信息增益

C4.5 ：信息增益+信息增益率，为减少信息增益准则对可取值数目较多的属性有所偏好而可能带来的不利影响。先从候选划分属性中找出信息增益高于平均水平的属性，再从中选择增益率最高的。

CART ：基尼系数

## 集成学习

### Bagging

并行训练一些分类器并将分类器的结果取平均

#### 		随机森林

数据采样和特征选择随机的树模型集合。

**数据采样。**如果想要集成学习的效果有比较好的泛化性能，那么集成中的基学习器应该尽可能地相互独立，但是这些学习器本来就是为了解决同一个问题而训练的，因此他们不可能完全独立。为了解决这个问题，可以将给定训练数据集划分成相互有交叠的子集供不同的基学习器训练，这样基学习器用各自带有一定差异并且体量依然能保持较大的数据集训练出的结果有不错的泛化性能。例如自助采样法（bootstrap sampling），包含m个数据的训练集，随机重复放回采样m次，得到可能包含重复值的大小为m的采样集，最后约有63.2%的训练集样本会出现在采样集中。

**随机特征选择。**在基决策树的特征选择中，对于每一个节点，先从该节点的特征集合中随机选择k个特征，然后再从这个特征子集中利用基于信息增益或基尼系数等划分方法选择出一个最优属性，用于在该节点数据集的划分。这种来自于属性层面的“扰动”进一步增加了基学习器之间的多样性，使得最终Bagging集成的泛化性能获得更多地提升。

**优势**

适合处理高纬度数据

高效，计算复杂度方面假设基学习器为O(m)，采样与投票/平均过程的复杂度为O (s)，则Bagging的复杂度为 T (O (m) + O (s))，考虑到T是一个较小的常数且采样与投票/平均过程的复杂度也很小，因此训练一个Bagging集成与单独训练一个基学习器的计算复杂度是同阶的。

### Boosting

并行训练一些分类器并将分类器的结果线性组合，弱学习器提升为强学习器。在训练集上训练出一个基学习器，再根据基学习器的表现对训练样本分布进行调整，使得先前基学习器做错的训练样本在后续受到更多关注。

#### 	[AdaBoost](https://www.cnblogs.com/ooon/p/5663975.html)

根据训练结果调整本轮样本的权重，从而改变样本的分布。

对于二分类问题： 

![image-20230713105501586](F:\Typora\pictures\image-20230713105501586.png)

- 对于迭代次数T的选择策略，可以限定收敛阈值，分类误差率小于某一个值就停止迭代；限定迭代次数，迭代1000次停止。
- 所有分类器权重之和并不为1
- 算法第 5 步中关于误差的判断，因为不满足准确性可能会带来负面效果，所以当误差率超过一半时，则会停止迭代，这样导致 Adaboost 执行不到预设的 M 轮，也就没有 M 个基学习器来做组合。这时可以抛弃当前误差较大的及学习器，按照该基学习器的结果重新调整样本权值，进而进入下一次迭代。

#### 	Gradient Boost

梯度提升背后的基本思想是在先前基学习器的残差（实际值和预测值之间的差）上迭代训练更多的基学习器。在每次迭代中，训练基学习器以最小化先前模型的残差。然后将所有基学习器的预测进行线性组合以做出最终预测。

梯度提升与其他Bagging集成的不同之处在于它训练基学习器的方式：梯度提升不是独立训练模型，而是以迭代的方式训练它们，每个模型都试图改进以前模型的错误，在梯度提升算法中将负梯度作为上一轮基学习器犯错的衡量指标。

梯度提升中的“梯度”是指使用梯度下降优化算法来最小化损失函数，并使用梯度下降来找到使这种差异最小化的最佳参数。梯度下降是经典的数值优化方法，其参数更新公式：

<img src="F:\Typora\pictures\image-20230714203455795.png" alt="image-20230714203455795" style="zoom: 80%;" />

Gradient Boosting 采用和AdaBoost同样的加法模型，在第m次迭代中，前m-1个基学习器都是固定的，即：

<img src="F:\Typora\pictures\image-20230714203941021.png" alt="image-20230714203941021" style="zoom: 80%;" />

因而在第m步我们的目标是最小化损失函数<img src="F:\Typora\pictures\image-20230714204058546.png" alt="image-20230714204058546" style="zoom: 70%;" />，求得第m个基学习器。

将参数的梯度下降推广到函数空间：

<img src="F:\Typora\pictures\image-20230714203900570.png" alt="image-20230714203900570" style="zoom: 80%;" />

所以有近似关系  ：

<img src="F:\Typora\pictures\image-20230714204406894.png" alt="image-20230714204406894" style="zoom: 67%;" />

即用基学习器hm(x)去拟合前一轮模型损失函数的负梯度。

#### 	XGBoost

精度提升方面，与GBDT不同的是XGBoost的目标函数包含损失函数和正则项两部分，其中损失函数代表着模型拟合数据的程度，而且在函数空间的梯度下降过程中使用了二阶导数来进一步考虑梯度变化的趋势，拟合更快，精度更高。在树模型中叶子节点越多模型越大，训练时间越长，并且很可能会导致模型过拟合从而导致预测结果变差，正则项被用来控制模型的复杂程度：树模型的叶子结点越多惩罚权重就越高，从而限制叶子节点数量。

速度提升方面，XGBoost在寻找最佳分割点时使用了一种预排序的机制并实现了并行计算，这里的并行计算是指在生成每棵树的时候能够并行计算所有特征的划分节点。XGBoost中将排好序的数据存储在内存单元中，称之为block。每个block中的数据根据每列特征取值排序，并以压缩列（CSC）格式储存。这种输入数据布局只需要在训练前计算一次，可以在后续迭代中重复使用。例如在寻找最优切分点划分的贪心算法算法中，将整个数据集存储在单个block中，并通过对预排序的数据进行线性扫描来实现分割点搜索。这样只需扫描一次block就可以得到所有特征所有候选分裂节点的统计信息。

## MLP

多层感知机是一种前馈式神经网络模型。它是一种具有多个隐藏层的神经网络，每个隐藏层由多个神经元节点组成，多层感知机通过学习输入数据的非线性映射来实现复杂分类和回归任务。

具体来说，多层感知机的输入层接收原始数据，每个输入节点对应数据的一个特征，隐藏层通过一系列的线性变换和非线性激活函数将输入数据映射到更高维的特征空间中，以便更好地区分不同类别的数据。最后，输出层根据隐藏层的特征表示进行分类或回归预测。其中，如何确定数据映射函数以及输出层对于隐藏层特征的转化方式，取决于多层感知机中对应的权重。在训练过程中，多层感知机通常使用反向传播算法对各层进行权重学习，不断优化，该算法通过计算损失函数对网络参数的梯度，并根据梯度更新权重值，从而使得网络的输出结果逼近真实标签，并且可以使用不同的损失函数和优化算法来适应不同的任务需求。

### 常用的优化算法

Adam自适应梯度下降，它结合了动量梯度下降法和均方根传递梯度下降法的优点。对于权重求导，使用动量梯度下降的处理方法+偏差修正，以解决减小批量大小后数据不多引起的梯度在极值点摆动的问题；对于学习率，使用均方根传递梯度下降的处理方法+偏差修正，以动态调整各维度下降速度。（β1推荐0.9，β2推荐0.999，ε推荐10-8）



<img src="F:\Typora\pictures\image-20230722204732112.png" alt="image-20230722204732112" style="zoom:50%;" />

SGD

### 隐藏层结构的确定

对于一般简单的数据集，一两层隐藏层通常可以满足需求，对于涉及时间序列或计算机视觉的复杂数据集则需要额外增加层数，层数越深，理论上拟合函数的能力增强，效果按理说会更好，但是实际上更深的层数可能会带来过拟合的问题，同时也会增加训练难度，使模型难以收敛。

隐藏层中的神经元数量方面，使用太少的神经元将导致欠拟合。相反，使用过多的神经元可能会导致过拟合，当神经网络具有过多的节点时，训练集中包含的有限信息量不足以训练隐藏层中的所有神经元，即使训练数据包含的信息量足够，隐藏层中过多的神经元会增加训练时间，从而难以达到预期的效果。此外，一般神经元数量随着隐藏层深入而递减，因为浅层设置相对多的神经元可以学习很多低阶的特征馈入后续层中，深层的少量神经元融合出较高阶特征。供参考的神经元数量公式：

<img src="F:\Typora\pictures\image-20230723164523900.png" alt="image-20230723164523900" style="zoom: 80%;" />

## 遗传算法

**(1) 确定表示解空间的编码方式**

- 二进制编码
- 格雷编码
- 浮点数编码

**(2) 初始化种群，也就是初始化一些解作为种群中的个体**

**(3) 构造适应度函数F**

可能遇到个体们适应度值接近的情况，此时用尺度变化方法，目的是放大它们之间的差异

- 线性尺度变换

<img src="F:\Typora\pictures\v2-c34f1bbb6cb9994f36d7bc87cd47115a_720w.webp" alt="img"  />

- 幂乘尺度变换

![img](F:\Typora\pictures\v2-e59f3d1a2397f625451f78b325701e3d_720w.webp)

- 指数尺度变换

![img](F:\Typora\pictures\v2-d264c06876bb59f1334bc188bed796ad_720w.webp)

**(4) For：**

1.将种群个体分别带入适应度函数得出适值

2.确定选择策略，决定个体被选取的概率。从旧群体中以一定概率选择优良个体组成新的种群，以繁殖得到下一代个体。个体被选中的概率跟适应度值有关，个体适应度值越高，被选中的概率越大。如轮盘赌选择：

<img src="F:\Typora\pictures\image-20230802165937538.png" alt="image-20230802165937538" style="zoom: 67%;" />

3.交叉运算，从种群中随机选择两个个体，通过两个染色体的交换组合，把父串的优秀特征遗传给子串，从而产生新的优秀个体。

①单点交叉：

- 个体随机配对
- 随机确定一个交叉点位置
- 自交叉点起互换基因编码

②两点交叉

- 个体随机配对
- 随机确定两个交叉点位置
- 两个交叉点之间互换基因编码

③部分匹配交叉

.....

变异运算

①基本位变异：

- 随机确定个体基因的变异点位置
- 依概率将变异点基因值取反

......

## [数据预处理](https://github.com/Yimeng-Zhang/feature-engineering-and-feature-selection)

### 1.数据清洗

数据清洗过程的方法感觉是直接指出使用什么算法做，而相关性降维的需要根据题意分析，与对应方法的适用场景契合，要表明这个题使用这些算法是有根据的。

以下方法适用空缺值和异常值较多，不适合直接删除包含空缺、异常值样本的情况下。

找出所有空缺值和异常值，设值为0，剔除0比例高的特征与样本，补齐0值

#### 1.1值层面

空缺值，设0 

异常值，设0 ，判断异常值：拉依达准则、最大最小限幅

#### 1.2特征层面

删除0值比例超过一定阈值的特征

#### 1.3样本层面

删除0值异常值超过一定阈值的样本

#### 1.4零值补齐

[缺失值处理详解](https://zhuanlan.zhihu.com/p/137175585)

均值插补、中位数插补、众数插补（离散数据），sklearn有包

[KNN插补（K值的确定需要交叉验证，不推荐使用）](https://www.cnblogs.com/panchuangai/p/13390354.html)  sklearn.KNNImputer

[随机森林插值、拉格朗日插值](https://blog.csdn.net/qq_42374697/article/details/108481645)

### 2.数据归一化

### 3.根据相关性降维

#### 	考虑自变量与因变量之间的相关性

​	选择对因变量值影响较大的一些自变量

##### 				线性降维方法

​		LASSO回归

​		Pearson相关系数，处理正态分布数据

##### 				非线性降维方法

​		随机森林

​		XGBoost

##### 				不分是否线性

​		[灰色关联度分析](https://zhuanlan.zhihu.com/p/149479206?utm_source=wechat_timeline)

​		距离相关系数

#### 	考虑自变量之间的相关性

​	也就是要考虑自变量之间的独立性

​	PCA主成成分分析

​	高相关性滤波

### Weeds

遍历每一列的值，用准则判断异常值并修改成0

遍历每一列的值，0值比例超过阈值后删除此列

遍历每一列行值，0值比例超过阈值后删除此行









